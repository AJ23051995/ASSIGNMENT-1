{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fabbf5c",
   "metadata": {},
   "source": [
    "# QUESTION 1-\n",
    "Write a python program to display all the header tags from Wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d011b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=requests.get('https://en.wikipedia.org')\n",
    "soup=BeautifulSoup(url.text,'html.parser')\n",
    "story=soup.find_all(['h1','h2','h3'])\n",
    "for i in story:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be4557",
   "metadata": {},
   "source": [
    "# QUESTION -2\n",
    "Write a python program to display IMDB's Top rated 100 movies(i.e.name,rating,year of release)\n",
    "and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c16bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "#to collect the english translation of datas\n",
    "headers={'Accept-Language':'en-US,en;q=0.5'}\n",
    "#data of 50 movies in each page,hence each request fetches 50 movies data making it a total of 100 movies.\n",
    "request=requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc',headers=headers)\n",
    "request1=requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt',headers=headers)\n",
    "Soup=BeautifulSoup(request.content)\n",
    "Soup1=BeautifulSoup(request1.content)\n",
    "#append data of both Soup and Soup1\n",
    "Soup.append(Soup1)\n",
    "MoviesName=[]\n",
    "Year=[]\n",
    "Rating=[]\n",
    "movies=Soup.find_all(\"div\",class_='lister-item mode-advanced')\n",
    "for m in movies:\n",
    "    name=m.h3.a.text\n",
    "    year=m.h3.find('span',class_='lister-item-year text-muted unbold').text\n",
    "    rate=m.strong.text\n",
    "    MoviesName.append(name)\n",
    "    Year.append(year)\n",
    "    Rating.append(rate)\n",
    "Movies=pd.DataFrame({'Movie':MoviesName,'Year of Release':Year,'Rating':Rating},index=range(1,101))\n",
    "Movies.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb8fa4",
   "metadata": {},
   "source": [
    "# QUESTION-3\n",
    "Write a python program to display IMDB's top rated 100 indian movies(i.e.name,rating,year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c40a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "req=requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "Soup=BeautifulSoup(req.content)\n",
    "movs=Soup.find_all('td',class_='titleColumn')\n",
    "movs100=movs[0:100]\n",
    "Mname=[]\n",
    "Year=[]\n",
    "for m in movs100:\n",
    "    name=m.a.text\n",
    "    year=m.span.text\n",
    "    Mname.append(name)\n",
    "    Year.append(year)\n",
    "rate=Soup.find_all('td',class_='ratingColumn imdbRating')\n",
    "rate100=rate[0:100]\n",
    "IMDB=[]\n",
    "for r in rate100:\n",
    "    imdb=r.strong.text\n",
    "    IMDB.append(imdb)\n",
    "INDTOP=pd.DataFrame({'Name':Mname,'Year of Release':Year,'Rating':IMDB},index=range(1,101))\n",
    "INDTOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7bbffc",
   "metadata": {},
   "source": [
    "# QUESTION-4\n",
    "Write apython program to display list of respected former presidents of India(i.e.Name,Term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6dce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "first_title=soup.find('h3')\n",
    "first_title\n",
    "\n",
    "\n",
    "first_title=[]\n",
    "for i in soup.find_all('h3'):\n",
    "    first_title.append(i.text)\n",
    "first_title\n",
    "\n",
    "\n",
    "Term=[]\n",
    "for i in soup.find_all('p'):\n",
    "    Term.append(i.text)\n",
    "Term\n",
    "\n",
    "\n",
    "Detail=[]\n",
    "for i in soup.find_all('div', class_=\"presidentListing\"):\n",
    "    Detail.append(i.text)\n",
    "Detail\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"PresidentiaL List\":Detail})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c912f38",
   "metadata": {},
   "source": [
    "# QUESTION-5\n",
    "Write a python program to scrape cricket ranking from icc-cricket.com.You have to scrape:\n",
    "\n",
    "a-Top 10 ODI Team in men's Cricket along with records of matches,points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a986f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "info=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup=BeautifulSoup(info.content)\n",
    "team=soup.find_all('tr',class_=('rankings-block__banner','table-body'))\n",
    "top10=team[0:10]\n",
    "data = {'Team_Name':[],'Matches': [],'Points': [],'Rating':[]}\n",
    "for i in top10:\n",
    "    pnt=i.find_all('td',recursive=True)\n",
    "    data['Team_Name'].append(i.find('span',class_='u-hide-phablet').text)\n",
    "    data['Matches'].append(pnt[2].text)\n",
    "    data['Points'].append(pnt[3].text)\n",
    "    data['Rating'].append(pnt[4].text.replace('\\n',''))\n",
    "MenTeam=pd.DataFrame(data,index=range(1,11))\n",
    "MenTeam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc0dbd2",
   "metadata": {},
   "source": [
    "# QUESTION-5\n",
    "b-Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "req=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup=BeautifulSoup(req.content)\n",
    "bowler=soup.find_all('tr',class_=('rankings-block__banner','table-body'))\n",
    "Top10=bowler[0:10]\n",
    "bdata={'Player_Name':[],'Team_Name': [], 'Rating':[]}\n",
    "for i in Top10:\n",
    "    bat=i.find_all('td',recursive=True)\n",
    "    bdata['Player_Name'].append(bat[1].text.replace('\\n',''))\n",
    "    bdata['Team_Name'].append(bat[2].text.replace('\\n',''))\n",
    "    bdata['Rating'].append(bat[3].text.replace('\\n',''))\n",
    "ODIBOWL=pd.DataFrame(bdata,index=range(1,11))\n",
    "ODIBOWL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1233a2f",
   "metadata": {},
   "source": [
    "# QUESTION-5\n",
    "c-TOP 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783898d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "req=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup=BeautifulSoup(req.content)\n",
    "player=soup.find_all('tr',class_=('rankings-block__banner','table-body'))\n",
    "Top10=player[0:10]\n",
    "data={'Player_Name':[],'Team_Name': [], 'Rating':[]}\n",
    "for i in Top10:\n",
    "    bat=i.find_all('td',recursive=True)\n",
    "    data['Player_Name'].append(bat[1].text.replace('\\n',''))\n",
    "    data['Team_Name'].append(bat[2].text.replace('\\n',''))\n",
    "    data['Rating'].append(bat[3].text.replace('\\n',''))\n",
    "ODIBATSMAN=pd.DataFrame(data,index=range(1,11))\n",
    "ODIBATSMAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f6f1b",
   "metadata": {},
   "source": [
    "# QUESTION-6\n",
    "Write a python program to scrape cricket rankings from icc-cricket.com.You have to scrape:\n",
    "\n",
    "a-Top 10 ODI teams in womens cricket along with the records of matches,points and rating.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "req=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup=BeautifulSoup(req.content)\n",
    "team=soup.find_all('tr',class_=('rankings-block__banner','table-body'))\n",
    "top10=team[0:10]\n",
    "data = {'Team_Name':[],'Matches': [],'Points': [],'Rating':[]}\n",
    "\n",
    "for i in top10:\n",
    "    pnt=i.find_all('td',recursive=True)\n",
    "    data['Team_Name'].append(i.find('span',class_='u-hide-phablet').text)\n",
    "    data['Matches'].append(pnt[2].text)\n",
    "    data['Points'].append(pnt[3].text)\n",
    "    data['Rating'].append(pnt[4].text.strip().replace('\\n',''))\n",
    "WomenTeam=pd.DataFrame(data,index=range(1,11))\n",
    "WomenTeam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf8ed8",
   "metadata": {},
   "source": [
    "# QUESTION-6\n",
    "b-Top 10 women's ODI batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "req=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')\n",
    "soup=BeautifulSoup(req.content)\n",
    "bowler=soup.find_all('tr',class_=('rankings-block__banner','table-body'))\n",
    "Top10=bowler[0:10]\n",
    "bdata={'Player_Name':[],'Team_Name': [], 'Rating':[]}\n",
    "for i in Top10:\n",
    "    bat=i.find_all('td',recursive=True)\n",
    "    bdata['Player_Name'].append(bat[1].text.replace('\\n',''))\n",
    "    bdata['Team_Name'].append(bat[2].text.replace('\\n',''))\n",
    "    bdata['Rating'].append(bat[3].text.replace('\\n',''))\n",
    "ODIBOWL=pd.DataFrame(bdata,index=range(1,11))\n",
    "ODIBOWL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c157155d",
   "metadata": {},
   "source": [
    "# QUESTION -6\n",
    "C-TOP 10 Women's ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "req=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "soup=BeautifulSoup(req.content)\n",
    "player=soup.find_all('tr',class_=('rankings-block__banner','table-body'))\n",
    "Top10=player[0:10]\n",
    "data={'Player_Name':[],'Team_Name': [], 'Rating':[]}\n",
    "for i in Top10:\n",
    "    bat=i.find_all('td',recursive=True)\n",
    "    data['Player_Name'].append(bat[1].text.replace('\\n',''))\n",
    "    data['Team_Name'].append(bat[2].text.replace('\\n',''))\n",
    "    data['Rating'].append(bat[3].text.replace('\\n',''))\n",
    "ODIBATSMAN=pd.DataFrame(data,index=range(1,11))\n",
    "ODIBATSMAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b107a32",
   "metadata": {},
   "source": [
    "# QUESTION-7\n",
    " write a python program to scrape mentioned nnews details from https://www.cnbc.com/world/?region=world:\n",
    " \n",
    " a)HEADLINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page\n",
    "\n",
    "news=BeautifulSoup(page.content)\n",
    "news\n",
    "\n",
    "# # Headline\n",
    "Headline=news.find('div',class_='RiverHeadline-headline RiverHeadline-hasThumbnail')\n",
    "Headline\n",
    "\n",
    "Headline.text\n",
    "\n",
    "Headline=[]\n",
    "for i in news.find_all('div',class_='RiverHeadline-headline RiverHeadline-hasThumbnail'):\n",
    "   Headline.append(i.text)\n",
    "Headline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24acb32",
   "metadata": {},
   "source": [
    "# QUESTION-7\n",
    "\n",
    "b)TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ee945",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time=news.find('time')\n",
    "Time\n",
    "\n",
    "\n",
    "Time.text\n",
    "\n",
    "\n",
    "Time=[]\n",
    "for i in news.find_all('time'):\n",
    "   Time.append(i.text)\n",
    "Time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465581e1",
   "metadata": {},
   "source": [
    "# QUESTION-7\n",
    "\n",
    "NEWSLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcabaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Newslink\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "webpage = requests.get(url) \n",
    "trav = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "for link in trav.find_all('a'):\n",
    "    print(type(link), \" \", link)\n",
    "\n",
    "\n",
    "trav.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258b710",
   "metadata": {},
   "source": [
    "# QUESTION 8\n",
    "Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape mentioned below Details:\n",
    "\n",
    "i)TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2751ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import re\n",
    "import pandas as pd \n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "\n",
    "data = rq.get(url)\n",
    "html_data = data.content\n",
    " \n",
    "Soup = bs(data.text, 'html.parser')\n",
    " \n",
    "header_data = Soup.find_all('h2')\n",
    "\n",
    "print('Following is the of most downloaded articles TITLES referred from', url, ':', '\\n')\n",
    "a=1\n",
    "for i in header_data:\n",
    "    print(a,'.',i.text.strip())\n",
    "    a = a+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626fecf3",
   "metadata": {},
   "source": [
    "# QUESTION-8\n",
    "\n",
    "ii)AUTHORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fea21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import re\n",
    "import pandas as pd \n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "\n",
    "\n",
    "data = rq.get(url)\n",
    "html_data = data.content\n",
    " \n",
    "Soup = bs(html_data, 'html.parser')\n",
    " \n",
    "header_data = Soup.find_all(class_='sc-1w3fpd7-0 pgLAT',)\n",
    "\n",
    "print('Following is the of most downloaded authors referred from', url, ':', '\\n')\n",
    "a=1\n",
    "for i in header_data:\n",
    "    print(a,'.',i.text.strip())\n",
    "    a = a+1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a72624",
   "metadata": {},
   "source": [
    "# QUESTION-8\n",
    "\n",
    "iii)PUBLISHED DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b901f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import re\n",
    "import pandas as pd \n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "\n",
    "\n",
    "data = rq.get(url)\n",
    "html_data = data.content\n",
    " \n",
    "Soup = bs(html_data, 'html.parser')\n",
    " \n",
    "header_data = Soup.find_all(class_='sc-1thf9ly-2 bKddwo',)\n",
    "\n",
    "print('Following is the of Dates for most downloaded authors referred from', url, ':', '\\n')\n",
    "a=1\n",
    "for i in header_data:\n",
    "    print(a,'.',i.text.strip())\n",
    "    a = a+1\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cd763",
   "metadata": {},
   "source": [
    "# QUESTION-8\n",
    "\n",
    "iv)PAPER URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22523056",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles '\n",
    "data = rq.get(url)\n",
    "html_data = data.content\n",
    " \n",
    "Soup = bs(data.text, 'html.parser')\n",
    " \n",
    "\n",
    "header_data = Soup.find_all('a',)\n",
    "\n",
    "for a in header_data:\n",
    "    print ( \"News URL:\", a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240790a",
   "metadata": {},
   "source": [
    "# QUESTION-9\n",
    "Write a python program to scrape details from mention details from dineout.co.in\n",
    "\n",
    "i)Restaurant name\n",
    "\n",
    "ii)cuisine\n",
    "\n",
    "iii)location\n",
    "\n",
    "Iv)Ratings\n",
    "\n",
    "v)image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.dineout.co.in/delhi-restaurants/welcome-back')\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "RN=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    RN.append(i.text)\n",
    "    \n",
    "RN\n",
    "\n",
    "\n",
    "price=[]\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    price.append(i.text)\n",
    "    \n",
    "price\n",
    "\n",
    "\n",
    "location=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "location\n",
    "\n",
    "\n",
    "images=[]\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    images.append(i['data-src'])\n",
    "    \n",
    "images\n",
    "\n",
    "\n",
    "RT=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    RT.append(i.text)\n",
    "    \n",
    "RT\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Restaurant Name\":RN, \"Cusines\":price, \"Location\":location, \"Ratings\":RT,\"Images_Url\":images})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b49de2",
   "metadata": {},
   "source": [
    "# QUESTION-10\n",
    "Write a python program to scrape the details of top publication from Google Scholar from\n",
    "\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page\n",
    "\n",
    "\n",
    "book=BeautifulSoup(page.content)\n",
    "book\n",
    "\n",
    "\n",
    "Rank=[]\n",
    "for i in book.find_all('td',class_='gsc_mvt_p'):\n",
    "   Rank.append(i.text)\n",
    "Rank\n",
    "\n",
    "\n",
    "Pub=[]\n",
    "for i in book.find_all('td',class_='gsc_mvt_t'):\n",
    "   Pub.append(i.text)\n",
    "Pub\n",
    "\n",
    "\n",
    "H5=[]\n",
    "for i in book.find_all('a',class_='gs_ibl gsc_mp_anchor'):\n",
    "   H5.append(i.text)\n",
    "H5\n",
    "\n",
    "\n",
    "h5=[]\n",
    "for i in book.find_all('span',class_='gs_ibl gsc_mp_anchor'):\n",
    "   h5.append(i.text)\n",
    "h5\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Rank\":Rank,\"Publication\":Pub,\"H5 Ixdex\":H5,\"H5 Median\":h5})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af63249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
